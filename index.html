<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>SN-NIR</title>

    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- <link rel='icon' href='./assets/icons/rnb.png' sizes='472x472'> -->

    <link href="./neural/npm/bootstrap%405.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-GLhlTQ8iRABdZLl6O3oVMWSktQOp6b7In1Zl3/Jr59b6EGGoI1aFkw7cmDA6j6gD" crossorigin="anonymous">

    <script src="./neural/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <!-- <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300,700' rel='stylesheet' type='text/css'> -->

    <link rel="stylesheet" href="./js/dics/dics.original.css">
    <script src="./js/dics/dics.original.js"></script>
    <script src="./js/event_handler.js"></script>

    <link href="./neural/css?family=IBM+Plex+Sans:300,400,500,600,700" rel="stylesheet">
    <link href="./neural/css-1?family=Inconsolata:300,400,500,600,700" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="./css/style_neural.css">
</head>

<body lang="en">
    <main role="main">

        <section class="jumbotron text-center" id="banner">
            <div class="container text-center" id="title">
                <h2 class="jumbotron-heading text-center" style="line-height: 35px;">
                   Normal-guided Detail-Preserving Neural Implicit Functions for High-Fidelity 3D Surface Reconstruction
                </h2>
                
            </div>

            <div class="container" style="max-width: none; margin-top:10px;">

                <div class="row row-author" style="margin: 0 70px 0 70px; ">
                    <div class="col-md author">
                        <a class="link">Anonymous Authors</a><sup style="margin-right:10px"></sup>
<!--                         <a class="link" href="./index.html" target="_blank">Robin Bruneau</a><sup>1,2,*</sup> -->
                    </div>   
<!--                 </div>
                <div class="col-md" style="margin-top: 0px;"></div>
                <div class="row row-author" style="margin: 0 70px 0 70px;">
					<div class="col-md author">
                        <a href="https://sites.google.com/view/yvainqueau/" target="_blank">Yvain Quéau</a><sup style="margin-right:10px">3</sup>
                        <a href="https://scholar.google.fr/citations?user=t9PRZ3AAAAAJ&hl=en" target="_blank">Jean Mélou</a><sup style="margin-right:10px">1</sup>
                        <a href="https://loutchoa.github.io/" target="_blank">François Lauze</a><sup style="margin-right:10px">2</sup>
                        <a href="https://www.irit.fr/~Jean-Denis.Durou/" target="_blank">Jean-Denis Durou</a><sup style="margin-right:10px">1</sup>
                        <a href="https://fr.linkedin.com/in/lilian-calvet-42b1a689" target="_blank">Lilian Calvet</a><sup>4</sup>
                    </div>
                </div> -->

<!--                 <div class="row" style="margin-top:0.5rem; margin-left: auto; margin-right: auto;">
                    <div class="col-md">
                        <div id="affiliation">
                            <sup>1</sup>IRIT, University of Toulouse, France &nbsp;&nbsp;&nbsp;&nbsp; 
                            <sup>2</sup>DIKU, University of Copenhagen, Denmark
                        </div>
                    </div>
                </div> -->
<!--                 <div class="row" style="margin-top:-1rem; margin-left: auto; margin-right: auto;">
                    <div class="col-md">
                        <div id="affiliation"> 
                            <sup>3</sup>GREYC, University of Caen, France &nbsp;&nbsp;&nbsp;&nbsp; 
                            <sup>4</sup>OR-X, Balgrist, University of Zurich, Switzerland
                        </div>
                    </div>
                </div>
            </div> -->

<!--             <div id="venue">
                IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024<br><br>
            </div> -->

            <div class="row">
                <div class="col-md">
                    <ul class="nav nav-pills">
                        <li style="padding-top: 10px;" class="space-between">
                            <a href="https://sn-nir.github.io/" class="hover-image-link" style="padding-top: 0;">
                            <image class="first-image" src="./assets/icons/paper.png" width="60px"></image>
                            <image class="second-image" src="./assets/icons/paper_hover.png" width="60px"></image>
                            <h3 style="font-size: 1.2rem; padding-top: 10px;"><strong>Paper</strong></h3>
                            </a>
                        </li>
                        <li style="padding-top: 10px;"  class="space-between">
                            <a href="https://github.com/sn-nir/sn-nir" class="hover-image-link" >
                            <image class="first-image" src="./assets/icons/github.png" width="60px"></image>
                            <image class="second-image" src="./assets/icons/github_hover.png" width="60px"></image>
                            <h3 style="font-size: 1.2rem; padding-top: 10px;"><strong>Code</strong></h3>
                            </a>
                        </li>
                    </ul>
                </div>
            </div>

            <!-- Add a sentence in bold centered saying this: /!\ A real-time CUDA implementation is coming soon. /!\ -->
            <div class="container" style="padding-top: 20px;">
        </section>
    </main>


    <div class="container">

        <hr style="border-top: 3px double;">

        <!-- Abstract -->
        <h5>Abstract</h5>
        <p style="text-align: justify; padding-bottom: 30px;">
            Neural implicit representations have emerged as a powerful paradigm for 3D reconstruction. However, despite their success, existing methods fail to capture fine geometric details and
          thin structures, especially in scenarios where only sparse RGB views of the objects of interest are available. We hypothesize that current methods for learning neural implicit representations
          from RGB or RGBD images produce 3D surfaces with missing parts and details because they only rely on 0-order differential properties, i.e. the 3D surface points and their projections,
          as supervisory signals. Such properties, however, do not capture the local 3D geometry around the points and also ignore the interactions between points. This paper demonstrates that training neural representations with first-order differential properties, i.e. surface normals, leads to highly accurate 3D surface reconstruction even in situations
          where only as few as two RGB (front and back) images are available. Given multiview RGB images of an object of interest, we first compute the approximate surface normals in the image space
          using the gradient of the depth maps produced using an off-the-shelf monocular depth estimator such as Depth Anything model.
          An implicit surface regressor is then trained using a loss function that enforces the first-order differential properties of the regressed surface to match those estimated from Depth Anything.
          Our extensive experiments on a wide range of real and synthetic datasets show that the proposed method achieves an unprecedented level of reconstruction accuracy even when using as few as two RGB views.
          The detailed ablation study also demonstrates that normal-based supervision plays a key role in this significant improvement in performance, enabling the 3D reconstruction of intricate geometric details
          and thin structures that were previously challenging to capture.
        </p>

        <!-- Overview -->
        <h5>Overview</h5>
        <div class="text-center;" style="padding-top: 30px; padding-bottom: 30px">
            <image src="./assets/snnir/images/Methodology_snnir.jpg" class="img-responsive" alt="intro">
        </div>
        <p style="text-align: justify;">
            An overview of our method. Our method involves the following steps: (a) We cast camera rays from each pixel into the scene
             while sampling \(m\) points along the ray. (b) For each sampled point, we find the corresponding SDF \(\hat{q}\) and
              rendered RGB color \(\hat{c}\) using an SDF and Neural Renderer network, respectively. Then we use volume rendering in a
               differentiable manner to find the rendered color for each pixel. (c) Finally, we additionally supervise our network with
                Depth-Normal Consistency loss that enables the 3D reconstruction of intricate geometric details and
thin structures.
        </p>
		
        <!-- Comparisons Videos -->
        <hr style="border-top: 3px double;">
        <h5>Rendering Results</h5>
        <h6>Rendering images with high-quality underliying geometry.</h6> 
        <div class="container;" style=" padding-bottom: 10px;">
            <ul class="nav nav-tabs nav-fill nav-justified" id="object-bmvsimages-render">
                <li class="nav-item">
                    <a class="nav-link" onclick="objectRenderEvent(0)">Bear</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectRenderEvent(1)">Camera</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectRenderEvent(2)">Clock</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectRenderEvent(3)">Dog</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link active" onclick="objectRenderEvent(4)">Durian</a>
                </li>
				<li class="nav-item">
                    <a class="nav-link" onclick="objectRenderEvent(5)">Gundam</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectRenderEvent(6)">Jade</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectRenderEvent(7)">Man</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectRenderEvent(8)">Stone</a>
                </li>
            </ul>
            <div class="bordered-container">
            <div class="b-dics" style="width: 100%; font-weight: 600; margin: 0 auto;">
                <img src="./assets/snnir/images/render_bmvs/durian/rgb.png" alt="RGB">
                <img src="./assets/snnir/images/render_bmvs/durian/normal.png" alt="Normal">
            </div>
            </div>
        </div>

        <hr style="border-top: 3px double;">
        <h5>Reconstruction Results</h5>

        <!-- <h6>Comparisons on DiLiGenT-MV</h6>
        <p style="text-align: justify;">
             Qualitative comparisons with the MVPS methods <a href="https://berk95kaya.github.io/UA_MVPS_project_page/">Kaya22</a>, 
            <a href="https://ywq.github.io/psnerf/">PS-NeRF</a>, 
            <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MVPSNet_Fast_Generalizable_Multi-view_Photometric_Stereo_ICCV_2023_paper.pdf">MVPSNet</a> 
            and <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Kaya_Multi-View_Photometric_Stereo_Revisited_WACV_2023_paper.pdf">Kaya23</a>. 
        </p>
        
        <div class="container;" style="padding-bottom: 10px;">
            <ul class="nav nav-tabs nav-fill nav-justified" id="video-changer">
                <li class="nav-item">
                    <a class="nav-link" onclick="changeVideo(0)">Bear</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link active" onclick="changeVideo(1)">Buddha</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="changeVideo(2)">Cow</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="changeVideo(3)">Pot2</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="changeVideo(4)">Reading</a>
                </li>
            </ul>
            
            <div>
                <video id="myVideo" width="100%" class="approach_video" controls="" autoplay="" muted="" loop="">
                    <source  src="./assets/rnb_neus/videos/cmp/buddha.mp4" type="video/mp4">
                </video>
            </div>
        </div> -->



        <!-- Comparisons Images -->
        <!-- <hr style="border-top: 3px double;"> -->
        <h6>Ours (mono-illumination) vs <a href="https://ywq.github.io/psnerf/">PS-NeRF</a> [ECCV 2022] (multi-illumination) vs <a href="https://lingjie0206.github.io/papers/NeuS/">NeuS [NeurIPS 2021]</a> (mono-illumination) on 2 views (front and back).</h6>

        <div class="container;" style=" padding-bottom: 10px;">
            <ul class="nav nav-tabs nav-fill nav-justified" id="object-scale-recon">
                <li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEvent(0)">Bear</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEvent(1)">Buddha</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEvent(2)">Cow</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link active" onclick="objectSceneEvent(3)">Pot2</a>
                </li>
				<li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEvent(4)">Reading</a>
                </li>
            </ul>
            <div class="bordered-container">
            <div class="b-dics" style="width: 70%; font-weight: 600; margin: 0 auto;">
                <img src="./assets/snnir/images/cmp_ps_methods/pot2/psnerf.png" alt="PS-NeRF">
                <img src="./assets/snnir/images/cmp_ps_methods/pot2/ours.png" alt="Ours">
                <img src="./assets/snnir/images/cmp_ps_methods/pot2/neus.png" alt="NeuS">
            </div>
            </div>
        </div>


        <!-- Comparisons Images -->
        <!-- <hr style="border-top: 3px double;"> -->
        <h6>Ours (mono-illumination) vs <a href="https://github.com/CyberAgentAILab/SuperNormal">Super Normal [CVPR 2024]</a> (multi-illumination) vs <a href="https://github.com/bbrument/RNb-NeuS/">RNb-NeuS [CVPR 2024]</a> (multi-illumination) on different number of views.</h6>

        <div class="container;" style=" padding-bottom: 10px; font-size: 0;">
            <ul class="nav nav-tabs nav-fill nav-justified" style="font-size: 16px;" id="modelChoice">
                <li class="nav-item">
                    <a class="nav-link" onclick="changeModel(0)">Bear</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="changeModel(1)">Buddha</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link active" onclick="changeModel(2)">Cow</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="changeModel(3)">Pot2</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="changeModel(4)">Reading</a>
                </li>
            </ul>
            <ul class="nav nav-tabs nav-fill nav-justified" id="viewChoice">
            <li class="nav-item" style="font-size: 16px;">
                <a class="nav-link active" onclick="changeView(0)">2 views</a>
            </li>
            <li class="nav-item" style="font-size: 16px;">
                <a class="nav-link" onclick="changeView(1)">5 views</a>
            </li>
            <li class="nav-item" style="font-size: 16px;">
                <a class="nav-link" onclick="changeView(2)">10 views</a>
            </li>
            <li class="nav-item" style="font-size: 16px;">
                <a class="nav-link" onclick="changeView(3)">15 views</a>
            </li>
            <li class="nav-item" style="font-size: 16px;">
                <a class="nav-link" onclick="changeView(4)">20 views</a>
            </li>
        </ul>
            <div class="bordered-container">
            <div class="b-dics" style="width: 70%; font-weight: 600; margin: 0 auto;">
                <img src="./assets/snnir/images/cmp_diff_views_methods/cow/sn_2.png" alt="Super Normal">
                <img src="./assets/snnir/images/cmp_diff_views_methods/cow/ours_2.png" alt="Ours">
                <img src="./assets/snnir/images/cmp_diff_views_methods/cow/rnb_neus_2.png" alt="RNb-NeuS">
            </div>
            </div>
        </div>


        <h6>Comparison to <a href="https://turandai.github.io/projects/gaussian_surfels/">Gaussian Surfels [SIGGRAPH 2024]</a> (SOTA) on BMVS dataset.</h6>

        <div class="container;" style=" padding-bottom: 10px;">
            <ul class="nav nav-tabs nav-fill nav-justified" id="object-bmvsobjects-recon">
                <li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEventBMVS(0)">Camera</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link active" onclick="objectSceneEventBMVS(1)">Clock</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEventBMVS(2)">Cow</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEventBMVS(3)">Dog</a>
                </li>
				<li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEventBMVS(4)">Man</a>
                </li>
            </ul>
            <div class="bordered-container">
            <div class="b-dics" style="width: 70%; font-weight: 600; margin: 0 auto;">
                <img src="./assets/snnir/images/cmp_bmvs/clock/gs.png" alt="Gaussian Surfels">
                <img src="./assets/snnir/images/cmp_bmvs/clock/ours.png" alt="Ours">
            </div>
            </div>
        </div>

        
        <h6>Comparison to <a href="https://turandai.github.io/projects/gaussian_surfels/">Gaussian Surfels [SIGGRAPH 2024]</a> (SOTA) on the DTU dataset on sparse (three) view setting.</h6>

        <div class="container;" style=" padding-bottom: 10px;">
            <ul class="nav nav-tabs nav-fill nav-justified" id="object-DTUobjects-recon">
                <li class="nav-item">
                    <a class="nav-link active" onclick="objectSceneEventDTU(0)">Scan 24</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEventDTU(1)">Scan 69</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEventDTU(2)">Scan 106</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEventDTU(3)">Scan 114</a>
                </li>
				<li class="nav-item">
                    <a class="nav-link" onclick="objectSceneEventDTU(4)">Scan 122</a>
                </li>
            </ul>
            <div class="bordered-container">
            <div class="b-dics" style="width: 70%; font-weight: 600; margin: 0 auto;">
                <img src="./assets/snnir/images/cmp_dtu/scan24/gs.png" alt="Gaussian Surfels">
                <img src="./assets/snnir/images/cmp_dtu/scan24/ours.png" alt="Ours">
            </div>
            </div>
        </div>

        <!-- Relighting video -->
        <!-- <hr style="border-top: 3px double;"> -->
<!--         <h6>Relighting with reflectance maps</h6>
        <p style="text-align: justify;">
            We provide additional results demonstrating relighting capabilities. 
            The videos show results under varying lighting conditions, with the reflectance, 
            roughness and metalness from <a href="https://github.com/satoshi-ikehata/SDM-UniPS-CVPR2023">SDM-UniPS</a> 
            used to create UV maps aligned with our 3D reconstruction results.
        </p> 
        <div class="container;" style="padding-bottom: 10px; width: 70%; margin: 0 auto;">
            <ul class="nav nav-tabs nav-fill nav-justified" id="video-changer-2">   
                <li class="nav-item">
                    <a class="nav-link" onclick="changeVideo2(0)">Bear</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="changeVideo2(1)">Buddha</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="changeVideo2(2)">Cow</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link  active" onclick="changeVideo2(3)">Pot2</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" onclick="changeVideo2(4)">Reading</a>
                </li>
            </ul>
            
            <div>
                <video id="myVideo2" width="100%" class="approach_video" controls="" autoplay="" muted="" loop="">
                    <source  src="./assets/rnb_neus/videos/relighting/pot2.mp4" type="video/mp4">
                </video>
            </div>
        </div>
 -->
  
        
        <!--
        <hr style="border-top: 3px double;">
        <h5>Approach</h5>
        <div class="container; padding-bottom: 10px;">
            <div>
                RNb-Neus builds on top of <a href="https://lingjie0206.github.io/papers/NeuS/">SDF-based volume rendering</a>.
            </div>

            <div>
                <br>
                <h6 style="margin-bottom: 30px;">1.&nbsp;&nbsp;Overview</h6>

                <p style="text-align: justify;"">
                    Given multi-view and multi-light images of an object acquired from N sparse views, 
                    our proposed methodology employs a two-step process. Initially, it utilizes a Photometric 
                    Stereo (PS) solution—specifically, SDM-UniPS as detailed in our paper—to derive reflectance 
                    and albedo maps. Subsequently, we leverage this information to generate simulated data adhering 
                    to a purely Lambertian model. The subsequent step involves the application of the NeuS architecture.
                    This architecture facilitates volume rendering employing a Lambertian approach by utilizing the 
                    normals of the Neural Signed Distance Function (SDF) alongside a network that predicts albedo at 
                    any spatial point. The optimization process involves minimizing the disparity between our simulated 
                    images and the rendered images, ultimately yielding a refined Neural SDF that accurately represents 
                    the object under consideration.
                </p>
                
                <div class="text-center;"" style="padding-top: 30px; padding-bottom: 30px">
                    <image src="./assets/rnb_neus/images/pipeline.png" class="img-responsive padding-top: 100px" alt="overview">
                </div>
            </div>
        </div>
		-->

        <!-- Citation -->
        <!-- <hr style="border-top: 3px double;">
        <h5>Citation</h5>
        <div class="row">
            <div id="citation">
                @inproceedings{Anonymous,<br>
                &nbsp;&nbsp;title={Normal-guided Detail-Preserving Neural Implicit Functions  for High-Fidelity 3D Surface Reconstruction},<br>
                &nbsp;&nbsp;author={Anonymous Authors},<br>
                &nbsp;&nbsp;eprint={xxx.xxxx},<br>
                &nbsp;&nbsp;archivePrefix={arXiv},<br>
                &nbsp;&nbsp;year={2024}<br>
                }
            </div> 
        </div> -->
        <!-- <div style="text-align:center;">
            <button id="copy-button" class="copy-button" onclick="copyTextToClipboard()" >Copy</button>
        </div> -->

        <!-- Acknowledgements -->
<!--         <hr style="border-top: 3px double;">
        <h5>Acknowledgements</h5>
        <p style="text-align: justify;">
            Baptiste Brument's doctoral student fellowship is funded by the French Ministry of Higher Education and Research.
            Robin Bruneau's doctoral student fellowship is funded by the Danish project PHYLORAMA. This work was partly funded by the French National Research Agency through the LabCom project ALICIA-Vision.
            Lilian Calvet's postdoctoral fellowship is supported by the OR-X - a Swiss national research infrastructure for translational surgery - and associated funding by the University of Zürich and University Hospital Balgrist.
        </p> -->
    </div>

<div id="copyMessage">
    @inproceedings{Brument23,
        title={Normal-guided Detail-Preserving Neural Implicit Functions  for High-Fidelity 3D Surface Reconstruction},
        author={Baptiste Brument and Robin Bruneau and Yvain Quéau and Jean Mélou and François Lauze and Jean-Denis Durou and Lilian Calvet},
        booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
        year={2024}
    }
</div>

        <script>  
            function copyTextToClipboard() {
                // Get the text with line breaks
                const textWithLineBreaks = document.getElementById('copyMessage').innerHTML;

                // Copy the text to the clipboard
                navigator.clipboard.writeText(textWithLineBreaks)
                    .then(() => {
                        // Optionally, provide some feedback to the user
                        document.getElementById('copy-button').style.backgroundColor = 'green';
                        document.getElementById('copy-button').textContent = 'Copied';
                    })
                    .catch(err => {
                        console.error('Unable to copy text to clipboard', err);
                    });
                }
        </script>


    </div>

</body>

</html>
